{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.utils.project import get_project_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BlogSpider(scrapy.Spider):\n",
    "    name = 'blogspider'\n",
    "    start_urls = ['https://blog.scrapinghub.com']\n",
    "\n",
    "    def parse(self, response):\n",
    "        for title in response.css('h2.entry-title'):\n",
    "            yield {'title': title.css('a ::text').extract_first()}\n",
    "\n",
    "        for next_page in response.css('div.prev-post > a'):\n",
    "            yield response.follow(next_page, self.parse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-16 11:55:00 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: scrapybot)\n",
      "2017-09-16 11:55:00 [scrapy.utils.log] INFO: Overridden settings: {}\n",
      "2017-09-16 11:55:00 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2017-09-16 11:55:00 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2017-09-16 11:55:00 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2017-09-16 11:55:00 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2017-09-16 11:55:00 [scrapy.core.engine] INFO: Spider opened\n",
      "2017-09-16 11:55:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2017-09-16 11:55:00 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023\n",
      "2017-09-16 11:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://blog.scrapinghub.com> (referer: None)\n",
      "2017-09-16 11:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com>\n",
      "{'title': 'Scraping the Steam Game Store with Scrapy'}\n",
      "2017-09-16 11:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com>\n",
      "{'title': 'Do Androids Dream of Electric Sheep?'}\n",
      "2017-09-16 11:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com>\n",
      "{'title': 'Deploy your Scrapy Spiders from GitHub'}\n",
      "2017-09-16 11:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com>\n",
      "{'title': 'Looking Back at 2016'}\n",
      "2017-09-16 11:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com>\n",
      "{'title': 'How to Increase Sales with Online Reputation Management'}\n",
      "2017-09-16 11:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com>\n",
      "{'title': 'How to Build your own Price Monitoring Tool'}\n",
      "2017-09-16 11:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com>\n",
      "{'title': 'How You Can Use Web Data to Accelerate Your Startup'}\n",
      "2017-09-16 11:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com>\n",
      "{'title': 'An Introduction to XPath: How to Get Started'}\n",
      "2017-09-16 11:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com>\n",
      "{'title': 'Why Promoting Open Data Increases Economic Opportunities'}\n",
      "2017-09-16 11:55:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com>\n",
      "{'title': 'Interview: How Up Hail uses Scrapy to Increase Transparency'}\n",
      "2017-09-16 11:55:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://blog.scrapinghub.com/page/2/> (referer: https://blog.scrapinghub.com)\n",
      "2017-09-16 11:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/2/>\n",
      "{'title': 'How to Run Python Scripts in Scrapy Cloud'}\n",
      "2017-09-16 11:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/2/>\n",
      "{'title': 'Embracing the Future of Work: How To Communicate Remotely'}\n",
      "2017-09-16 11:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/2/>\n",
      "{'title': 'How to Deploy Custom Docker Images for Your Web Crawlers'}\n",
      "2017-09-16 11:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/2/>\n",
      "{'title': 'Improved Frontera: Web Crawling at Scale with Python 3 Support'}\n",
      "2017-09-16 11:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/2/>\n",
      "{'title': 'How to Crawl the Web Politely with Scrapy'}\n",
      "2017-09-16 11:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/2/>\n",
      "{'title': 'Introducing Scrapy Cloud with Python 3 Support'}\n",
      "2017-09-16 11:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/2/>\n",
      "{'title': 'What the Suicide Squad Tells Us About Web Data'}\n",
      "2017-09-16 11:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/2/>\n",
      "{'title': 'This Month in Open Source at Scrapinghub August 2016'}\n",
      "2017-09-16 11:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/2/>\n",
      "{'title': 'Meet Parsel: the Selector Library behind Scrapy'}\n",
      "2017-09-16 11:55:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/2/>\n",
      "{'title': 'Incremental Crawls with Scrapy and DeltaFetch'}\n",
      "2017-09-16 11:55:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://blog.scrapinghub.com/page/3/> (referer: https://blog.scrapinghub.com/page/2/)\n",
      "2017-09-16 11:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/3/>\n",
      "{'title': 'Improving Access to Peruvian Congress Bills with Scrapy'}\n",
      "2017-09-16 11:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/3/>\n",
      "{'title': 'Scrapely: The Brains Behind Portia Spiders'}\n",
      "2017-09-16 11:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/3/>\n",
      "{'title': 'Introducing Portia2Code: Portia Projects into Scrapy Spiders'}\n",
      "2017-09-16 11:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/3/>\n",
      "{'title': 'Scraping Infinite Scrolling Pages'}\n",
      "2017-09-16 11:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/3/>\n",
      "{'title': 'This Month in Open Source at Scrapinghub June 2016'}\n",
      "2017-09-16 11:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/3/>\n",
      "{'title': 'Introducing the Datasets Catalog'}\n",
      "2017-09-16 11:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/3/>\n",
      "{'title': 'Introducing the Crawlera Dashboard'}\n",
      "2017-09-16 11:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/3/>\n",
      "{'title': 'Data Extraction with Scrapy and Python 3'}\n",
      "2017-09-16 11:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/3/>\n",
      "{'title': 'How to Debug your Scrapy Spiders'}\n",
      "2017-09-16 11:55:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/3/>\n",
      "{'title': 'Scrapy + MonkeyLearn: Textual Analysis of Web Data'}\n",
      "2017-09-16 11:55:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://blog.scrapinghub.com/page/4/> (referer: https://blog.scrapinghub.com/page/3/)\n",
      "2017-09-16 11:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/4/>\n",
      "{'title': 'Introducing Scrapy Cloud 2.0'}\n",
      "2017-09-16 11:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/4/>\n",
      "{'title': 'A (not so) Short Story on Getting Decent Internet Access'}\n",
      "2017-09-16 11:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/4/>\n",
      "{'title': 'Scraping Websites Based on ViewStates with Scrapy'}\n",
      "2017-09-16 11:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/4/>\n",
      "{'title': 'Machine Learning with Web Scraping: New MonkeyLearn Addon'}\n",
      "2017-09-16 11:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/4/>\n",
      "{'title': 'Mapping Corruption in the Panama Papers with Open Data'}\n",
      "2017-09-16 11:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/4/>\n",
      "{'title': 'Web Scraping to Create Open Data'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-16 11:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/4/>\n",
      "{'title': 'Scrapy Tips from the Pros: March 2016 Edition'}\n",
      "2017-09-16 11:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/4/>\n",
      "{'title': 'This Month in Open Source at Scrapinghub March 2016'}\n",
      "2017-09-16 11:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/4/>\n",
      "{'title': 'Join Scrapinghub for Google Summer of Code 2016'}\n",
      "2017-09-16 11:55:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/4/>\n",
      "{'title': 'How Web Scraping is Revealing Lobbying and Corruption in Peru'}\n",
      "2017-09-16 11:55:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://blog.scrapinghub.com/page/5/> (referer: https://blog.scrapinghub.com/page/4/)\n",
      "2017-09-16 11:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/5/>\n",
      "{'title': 'Splash 2.0 Is Here with Qt 5 and Python 3'}\n",
      "2017-09-16 11:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/5/>\n",
      "{'title': 'Migrate your Kimono Projects to Portia'}\n",
      "2017-09-16 11:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/5/>\n",
      "{'title': 'Scrapy Tips from the Pros: February 2016 Edition'}\n",
      "2017-09-16 11:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/5/>\n",
      "{'title': 'Portia: The Open Source Alternative to Kimono Labs'}\n",
      "2017-09-16 11:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/5/>\n",
      "{'title': 'Web Scraping Finds Stores Guilty of Price Inflation'}\n",
      "2017-09-16 11:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/5/>\n",
      "{'title': 'Python 3 is Coming to Scrapy'}\n",
      "2017-09-16 11:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/5/>\n",
      "{'title': 'Happy Anniversary: Scrapinghub Turns 5'}\n",
      "2017-09-16 11:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/5/>\n",
      "{'title': 'Scrapy Tips from the Pros: Part 1'}\n",
      "2017-09-16 11:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/5/>\n",
      "{'title': 'Vizlegal: Rise of Machine-Readable Laws and Court Judgments'}\n",
      "2017-09-16 11:55:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/5/>\n",
      "{'title': 'Christmas Eve vs New Year’s Eve: Last Minute Price Inflation?'}\n",
      "2017-09-16 11:55:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://blog.scrapinghub.com/page/6/> (referer: https://blog.scrapinghub.com/page/5/)\n",
      "2017-09-16 11:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/6/>\n",
      "{'title': 'Looking Back at 2015'}\n",
      "2017-09-16 11:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/6/>\n",
      "{'title': 'Winter Sales Showdown: Black Friday vs Cyber Monday vs Green Monday'}\n",
      "2017-09-16 11:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/6/>\n",
      "{'title': 'Chats With RINAR Solutions'}\n",
      "2017-09-16 11:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/6/>\n",
      "{'title': 'Black Friday, Cyber Monday: Are They Worth It?'}\n",
      "2017-09-16 11:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/6/>\n",
      "{'title': 'Tips for Creating a Cohesive Company Culture Remotely'}\n",
      "2017-09-16 11:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/6/>\n",
      "{'title': 'Parse Natural Language Dates with Dateparser'}\n",
      "2017-09-16 11:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/6/>\n",
      "{'title': 'Aduana: Link Analysis to Crawl the Web at Scale'}\n",
      "2017-09-16 11:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/6/>\n",
      "{'title': 'Scrapy on the Road to Python 3 Support'}\n",
      "2017-09-16 11:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/6/>\n",
      "{'title': 'Introducing Javascript support for Portia'}\n",
      "2017-09-16 11:55:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/6/>\n",
      "{'title': 'Distributed Frontera: Web Crawling at Scale'}\n",
      "2017-09-16 11:55:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://blog.scrapinghub.com/page/7/> (referer: https://blog.scrapinghub.com/page/6/)\n",
      "2017-09-16 11:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/7/>\n",
      "{'title': 'The Road to Loading JavaScript in Portia'}\n",
      "2017-09-16 11:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/7/>\n",
      "{'title': 'EuroPython 2015'}\n",
      "2017-09-16 11:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/7/>\n",
      "{'title': 'StartupChats Remote Working Q&A'}\n",
      "2017-09-16 11:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/7/>\n",
      "{'title': 'PyCon Philippines 2015'}\n",
      "2017-09-16 11:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/7/>\n",
      "{'title': 'Google Summer of Code 2015'}\n",
      "2017-09-16 11:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/7/>\n",
      "{'title': 'Link Analysis Algorithms Explained'}\n",
      "2017-09-16 11:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/7/>\n",
      "{'title': 'EuroPython, here we go!'}\n",
      "2017-09-16 11:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/7/>\n",
      "{'title': 'Using git to manage vacations in a large distributed team'}\n",
      "2017-09-16 11:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/7/>\n",
      "{'title': 'Gender Inequality Across Programming Languages'}\n",
      "2017-09-16 11:55:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/7/>\n",
      "{'title': 'Traveling Tips for Remote Workers'}\n",
      "2017-09-16 11:55:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://blog.scrapinghub.com/page/8/> (referer: https://blog.scrapinghub.com/page/7/)\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/8/>\n",
      "{'title': 'A Career in Remote Working'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/8/>\n",
      "{'title': 'Frontera: The Brain Behind the Crawls'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/8/>\n",
      "{'title': 'Scrape Data Visually with Portia and Scrapy Cloud'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/8/>\n",
      "{'title': 'Scrapinghub: A Remote Working Success Story'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/8/>\n",
      "{'title': 'Why we moved to Slack'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/8/>\n",
      "{'title': 'The History of Scrapinghub'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/8/>\n",
      "{'title': 'Skinfer: A Tool for Inferring JSON Schemas'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/8/>\n",
      "{'title': 'Handling JavaScript in Scrapy with Splash'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/8/>\n",
      "{'title': 'Scrapinghub Crawls the Deep Web'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/8/>\n",
      "{'title': 'New Changes to Our Scrapy Cloud Platform'}\n",
      "2017-09-16 11:55:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://blog.scrapinghub.com/page/9/> (referer: https://blog.scrapinghub.com/page/8/)\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/9/>\n",
      "{'title': 'Introducing ScrapyRT: An API for Scrapy spiders'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/9/>\n",
      "{'title': 'Looking Back at 2014'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/9/>\n",
      "{'title': 'XPath Tips from the Web Scraping Trenches'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/9/>\n",
      "{'title': 'Introducing Data Reviews'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/9/>\n",
      "{'title': 'Extracting schema.org Microdata Using Scrapy Selectors and XPath'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/9/>\n",
      "{'title': 'Announcing Portia, the Open Source Visual Web Scraper!'}\n",
      "2017-09-16 11:55:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/9/>\n",
      "{'title': 'Optimizing Memory Usage of Scikit-Learn Models Using Succinct Tries'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/9/>\n",
      "{'title': 'Open Source at Scrapinghub'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/9/>\n",
      "{'title': 'Looking Back at 2013'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/9/>\n",
      "{'title': 'Marcos Campal Is a ScrapingHubber!'}\n",
      "2017-09-16 11:55:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://blog.scrapinghub.com/page/10/> (referer: https://blog.scrapinghub.com/page/9/)\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/10/>\n",
      "{'title': 'Introducing Dash'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/10/>\n",
      "{'title': 'Why MongoDB Is a Bad Choice for Storing Our Scraped Data'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/10/>\n",
      "{'title': 'Introducing Crawlera, a Smart Page Downloader'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/10/>\n",
      "{'title': 'Git Workflow for Scrapy Projects'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/10/>\n",
      "{'title': 'How to Fill Login Forms Automatically'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/10/>\n",
      "{'title': 'Spiders activity graphs'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/10/>\n",
      "{'title': 'Finding Similar Items'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/10/>\n",
      "{'title': 'Scrapy 0.15 dropping support for Python 2.5'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/10/>\n",
      "{'title': 'Autoscraping casts a wider net'}\n",
      "2017-09-16 11:55:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/10/>\n",
      "{'title': 'Scrapy 0.14 released'}\n",
      "2017-09-16 11:55:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://blog.scrapinghub.com/page/11/> (referer: https://blog.scrapinghub.com/page/10/)\n",
      "2017-09-16 11:55:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/11/>\n",
      "{'title': 'Dirbot – a new example Scrapy project'}\n",
      "2017-09-16 11:55:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/11/>\n",
      "{'title': 'Introducing w3lib and scrapely'}\n",
      "2017-09-16 11:55:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/11/>\n",
      "{'title': 'Scrapy 0.12 released'}\n",
      "2017-09-16 11:55:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/11/>\n",
      "{'title': 'Spoofing your Scrapy bot IP using tsocks'}\n",
      "2017-09-16 11:55:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://blog.scrapinghub.com/page/11/>\n",
      "{'title': 'Hello, world'}\n",
      "2017-09-16 11:55:10 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2017-09-16 11:55:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 2933,\n",
      " 'downloader/request_count': 11,\n",
      " 'downloader/request_method_count/GET': 11,\n",
      " 'downloader/response_bytes': 124177,\n",
      " 'downloader/response_count': 11,\n",
      " 'downloader/response_status_count/200': 11,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2017, 9, 16, 17, 55, 10, 941349),\n",
      " 'item_scraped_count': 105,\n",
      " 'log_count/DEBUG': 117,\n",
      " 'log_count/INFO': 7,\n",
      " 'request_depth_max': 10,\n",
      " 'response_received_count': 11,\n",
      " 'scheduler/dequeued': 11,\n",
      " 'scheduler/dequeued/memory': 11,\n",
      " 'scheduler/enqueued': 11,\n",
      " 'scheduler/enqueued/memory': 11,\n",
      " 'start_time': datetime.datetime(2017, 9, 16, 17, 55, 0, 706025)}\n",
      "2017-09-16 11:55:10 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess(get_project_settings())\n",
    "\n",
    "process.crawl(BlogSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
